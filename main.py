import os
import json
import pandas as pd
from openai import OpenAI
import time
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import re
from datetime import datetime
import warnings
import concurrent.futures
import threading

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
import platform

if platform.system() == 'Windows':
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
elif platform.system() == 'Darwin':
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Heiti TC']
else:
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'WenQuanYi Micro Hei']
plt.rcParams['axes.unicode_minus'] = False


class CSVToReviewsConverter:
    """å°†CSVæ ¼å¼çš„äºšé©¬é€Šè¯„è®ºè½¬æ¢ä¸ºåˆ†æç³»ç»Ÿå¯ç”¨çš„æ ¼å¼"""

    def __init__(self, csv_file_path, output_folder="reviews"):
        self.csv_file_path = csv_file_path
        self.output_folder = output_folder
        self.df = None

    def read_csv(self):
        """è¯»å–CSVæ–‡ä»¶"""
        try:
            self.df = pd.read_csv(self.csv_file_path, encoding='utf-8')
            print(f"âœ“ æˆåŠŸè¯»å–CSVæ–‡ä»¶: {self.csv_file_path}")
            print(f"  å…± {len(self.df)} æ¡è¯„è®º")

            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            print(f"  åˆ—å: {list(self.df.columns)}")

            # æ˜¾ç¤ºå‡ æ¡æ ·æœ¬æ•°æ®
            if len(self.df) > 0:
                print(f"\næ ·æœ¬æ•°æ®é¢„è§ˆ:")
                sample = self.df.iloc[0]
                print(f"  è¯„åˆ†: {sample['rating']}")
                print(f"  æ ‡é¢˜: {sample['title'][:50]}...")
                print(f"  æ­£æ–‡: {sample['body'][:100]}...")

            return True
        except Exception as e:
            print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
            return False

    def create_output_folder(self):
        """åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹"""
        if not os.path.exists(self.output_folder):
            os.makedirs(self.output_folder)
            print(f"âœ“ åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹: {self.output_folder}/")
        else:
            # æ¸…ç©ºå·²æœ‰çš„æ–‡ä»¶
            for file in os.listdir(self.output_folder):
                if file.endswith('.json'):
                    os.remove(os.path.join(self.output_folder, file))
            print(f"âœ“ æ¸…ç†è¾“å‡ºæ–‡ä»¶å¤¹: {self.output_folder}/")

    def convert_to_json_batch(self):
        """ç”ŸæˆJSONæ‰¹é‡æ–‡ä»¶ - ä¿®å¤ç‰ˆ"""
        print("æ­£åœ¨è½¬æ¢ä¸ºJSONæ–‡ä»¶...")

        reviews_list = []

        for idx, row in self.df.iterrows():
            # ç¡®ä¿æ­£ç¡®æå–æ¯ä¸ªå­—æ®µ
            try:
                # æ¸…ç†å’Œç»„åˆè¯„è®ºå†…å®¹
                title = str(row['title']).strip() if pd.notna(row['title']) else ""
                body = str(row['body']).strip() if pd.notna(row['body']) else ""

                # ç»„åˆæ ‡é¢˜å’Œæ­£æ–‡
                if title and body:
                    review_content = f"{title}. {body}"
                elif body:
                    review_content = body
                elif title:
                    review_content = title
                else:
                    continue  # è·³è¿‡ç©ºè¯„è®º

                # åˆ›å»ºè¯„è®ºå¯¹è±¡
                review_obj = {
                    'review': review_content,
                    'rating': float(row['rating']) if pd.notna(row['rating']) else 3.0,
                    'username': str(row['username']) if pd.notna(row['username']) else "Anonymous",
                    'date': str(row['date']) if pd.notna(row['date']) else "",
                    'product_title': str(row['product_title']) if pd.notna(row['product_title']) else ""
                }

                reviews_list.append(review_obj)

            except Exception as e:
                print(f"å¤„ç†ç¬¬{idx}è¡Œæ—¶å‡ºé”™: {e}")
                continue

        print(f"  æˆåŠŸå¤„ç† {len(reviews_list)} æ¡æœ‰æ•ˆè¯„è®º")

        # åˆ†æ‰¹ä¿å­˜
        batch_size = 20  # å‡å°æ‰¹æ¬¡å¤§å°
        file_count = 0

        for i in range(0, len(reviews_list), batch_size):
            batch = reviews_list[i:i + batch_size]
            filename = f"reviews_batch_{file_count + 1:03d}.json"
            filepath = os.path.join(self.output_folder, filename)

            # ä¿å­˜ä¸ºJSONæ ¼å¼
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(batch, f, ensure_ascii=False, indent=2)

            file_count += 1

        print(f"âœ“ å·²ç”Ÿæˆ {file_count} ä¸ªJSONæ–‡ä»¶")

        # éªŒè¯ç¬¬ä¸€ä¸ªæ–‡ä»¶
        first_file = os.path.join(self.output_folder, "reviews_batch_001.json")
        if os.path.exists(first_file):
            with open(first_file, 'r', encoding='utf-8') as f:
                sample_data = json.load(f)
                if sample_data and len(sample_data) > 0:
                    print(f"\néªŒè¯ç¬¬ä¸€æ¡è¯„è®º:")
                    print(f"  è¯„åˆ†: {sample_data[0].get('rating', 'N/A')}")
                    print(f"  å†…å®¹é•¿åº¦: {len(sample_data[0].get('review', ''))} å­—ç¬¦")

        return True

    def generate_csv_summary(self):
        """ç”ŸæˆCSVæ•°æ®æ‘˜è¦"""
        if self.df is None or self.df.empty:
            return

        print("\nğŸ“Š CSVæ•°æ®ç»Ÿè®¡:")
        print(f"  - æ€»è¯„è®ºæ•°: {len(self.df)}")

        # è¯„åˆ†åˆ†å¸ƒ
        rating_counts = self.df['rating'].value_counts().sort_index(ascending=False)
        print(f"\n  è¯„åˆ†åˆ†å¸ƒ:")
        for rating, count in rating_counts.items():
            percentage = (count / len(self.df)) * 100
            bar = "â–ˆ" * int(percentage / 2)
            print(f"    {rating:.1f}æ˜Ÿ: {count:3} æ¡ ({percentage:5.1f}%) {bar}")

        avg_rating = self.df['rating'].mean()
        print(f"\n  å¹³å‡è¯„åˆ†: {avg_rating:.2f}/5.0")

        # æ£€æŸ¥è¯„è®ºå†…å®¹
        self.df['review_length'] = self.df['body'].fillna('').str.len() + self.df['title'].fillna('').str.len()
        print(f"\n  è¯„è®ºé•¿åº¦:")
        print(f"    å¹³å‡: {self.df['review_length'].mean():.0f} å­—ç¬¦")
        print(f"    æœ€çŸ­: {self.df['review_length'].min()} å­—ç¬¦")
        print(f"    æœ€é•¿: {self.df['review_length'].max()} å­—ç¬¦")

    def convert(self):
        """æ‰§è¡Œè½¬æ¢"""
        if not self.read_csv():
            return False

        self.create_output_folder()
        self.generate_csv_summary()
        self.convert_to_json_batch()

        return True


class AmazonReviewAnalyzer:
    """äºšé©¬é€Šè¯„è®ºåˆ†æå™¨"""

    def __init__(self, api_key, reviews_folder="reviews", use_api=False):
        self.api_key = api_key
        self.reviews_folder = reviews_folder
        self.results = []
        self.themes = []
        self.product_insights = {}
        self.use_api = use_api
        self.api_call_count = 0
        self.lock = threading.Lock()

        if use_api:
            try:
                self.client = OpenAI(
                    api_key=api_key,
                    base_url="https://api.deepseek.com"
                )
                print("âœ“ DeepSeek APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ APIåˆå§‹åŒ–å¤±è´¥ï¼Œåˆ‡æ¢åˆ°æœ¬åœ°æ¨¡å¼: {e}")
                self.use_api = False

    def read_reviews(self):
        """è¯»å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰è¯„è®º"""
        reviews = []

        if not os.path.exists(self.reviews_folder):
            print(f"æ–‡ä»¶å¤¹ '{self.reviews_folder}' ä¸å­˜åœ¨")
            return reviews

        file_count = 0
        for filename in os.listdir(self.reviews_folder):
            if filename.startswith('_'):
                continue

            file_path = os.path.join(self.reviews_folder, filename)

            if filename.endswith('.json'):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            for item in data:
                                if 'review' in item:
                                    reviews.append({
                                        'filename': filename,
                                        'content': item['review'],
                                        'rating': item.get('rating', None)
                                    })
                        file_count += 1
                except Exception as e:
                    print(f"è¯»å–æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")

        if reviews:
            print(f"âœ“ æˆåŠŸè¯»å– {len(reviews)} æ¡è¯„è®ºï¼ˆæ¥è‡ª {file_count} ä¸ªæ–‡ä»¶ï¼‰")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¯„è®ºæ–‡ä»¶")

        return reviews

    def local_sentiment_analysis(self, text, rating=None):
        """æ”¹è¿›çš„æœ¬åœ°æƒ…æ„Ÿåˆ†æ - è€ƒè™‘è¯„åˆ†"""
        text_lower = text.lower()

        # å¦‚æœæœ‰è¯„åˆ†ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨è¯„åˆ†åˆ¤æ–­
        if rating is not None:
            if rating >= 4.5:
                base_sentiment = 'positive'
                base_score = 4.5
            elif rating >= 3.5:
                base_sentiment = 'positive'
                base_score = 4.0
            elif rating >= 2.5:
                base_sentiment = 'neutral'
                base_score = 3.0
            elif rating >= 1.5:
                base_sentiment = 'negative'
                base_score = 2.0
            else:
                base_sentiment = 'negative'
                base_score = 1.5
        else:
            base_sentiment = 'neutral'
            base_score = 3.0

        # åˆ†ææ–‡æœ¬å†…å®¹è¿›è¡Œè°ƒæ•´

        # å¼ºçƒˆæ­£é¢çŸ­è¯­
        strong_positive_phrases = [
            'highly recommend', 'absolutely love', 'perfect', 'amazing', 'excellent',
            'best purchase', 'very satisfied', 'works perfectly', 'five stars',
            'exceeded expectations', 'fantastic', 'outstanding', 'incredible'
        ]

        # å¼ºçƒˆè´Ÿé¢çŸ­è¯­
        strong_negative_phrases = [
            'very disappointed', 'waste of money', 'do not buy', 'terrible', 'horrible',
            'poor quality', 'broke', 'doesn\'t work', 'defective', 'worst',
            'not worth', 'avoid', 'scam', 'trash', 'garbage', 'awful',
            'returned', 'refund', 'broken', 'useless', 'cheap quality'
        ]

        # ä¸­æ€§çŸ­è¯­
        neutral_phrases = [
            'okay', 'fine', 'decent', 'average', 'not bad', 'alright',
            'acceptable', 'fair', 'reasonable', 'so-so'
        ]

        # æ£€æŸ¥å¼ºçƒˆçŸ­è¯­
        has_strong_positive = any(phrase in text_lower for phrase in strong_positive_phrases)
        has_strong_negative = any(phrase in text_lower for phrase in strong_negative_phrases)
        has_neutral = any(phrase in text_lower for phrase in neutral_phrases)

        # è°ƒæ•´æƒ…æ„Ÿåˆ¤æ–­
        if has_strong_negative:
            sentiment = 'negative'
            score = min(base_score - 1, 2.0)
        elif has_strong_positive:
            sentiment = 'positive'
            score = max(base_score + 0.5, 4.0)
        elif has_neutral:
            sentiment = 'neutral'
            score = 3.0
        else:
            # è®¡ç®—ä¸€èˆ¬æ­£è´Ÿè¯æ±‡
            positive_words = ['good', 'great', 'nice', 'love', 'happy', 'satisfied', 'recommend', 'quality']
            negative_words = ['bad', 'poor', 'disappointed', 'issue', 'problem', 'wrong', 'not working']

            positive_count = sum(1 for word in positive_words if word in text_lower)
            negative_count = sum(1 for word in negative_words if word in text_lower)

            if negative_count > positive_count:
                sentiment = 'negative'
                score = min(base_score - 0.5, 2.5)
            elif positive_count > negative_count:
                sentiment = 'positive'
                score = max(base_score, 3.5)
            else:
                sentiment = base_sentiment
                score = base_score

        return {
            'sentiment': sentiment,
            'score': round(score, 1),
            'keywords': self.extract_keywords(text_lower),
            'pros': self.extract_pros(text_lower),
            'cons': self.extract_cons(text_lower),
            'summary': text[:100] + "..." if len(text) > 100 else text
        }

    def extract_keywords(self, text_lower):
        """æå–å…³é”®è¯"""
        keywords = []
        important_words = ['quality', 'price', 'shipping', 'delivery', 'design',
                           'battery', 'screen', 'performance', 'value', 'packaging']
        for word in important_words:
            if word in text_lower:
                keywords.append(word)
        return keywords[:5] if keywords else ['product']

    def extract_pros(self, text_lower):
        """æå–ä¼˜ç‚¹"""
        pros = []
        pros_patterns = {
            'good quality': ['good quality', 'high quality', 'well made', 'durable', 'solid', 'sturdy'],
            'fast delivery': ['fast shipping', 'quick delivery', 'arrived quickly', 'fast delivery'],
            'good value': ['good price', 'great value', 'worth the money', 'affordable'],
            'great design': ['beautiful', 'sleek', 'nice design', 'looks great'],
            'easy to use': ['easy to use', 'user friendly', 'intuitive', 'simple']
        }
        for pro, patterns in pros_patterns.items():
            if any(pattern in text_lower for pattern in patterns):
                pros.append(pro)
        return pros

    def extract_cons(self, text_lower):
        """æå–ç¼ºç‚¹"""
        cons = []
        cons_patterns = {
            'poor quality': ['poor quality', 'cheap', 'flimsy', 'broke', 'fragile', 'low quality'],
            'shipping issues': ['late delivery', 'delayed', 'slow shipping', 'damaged', 'poor packaging'],
            'overpriced': ['expensive', 'overpriced', 'not worth', 'too much'],
            'technical issues': ['doesn\'t work', 'not working', 'defective', 'malfunction', 'glitch'],
            'poor design': ['uncomfortable', 'awkward', 'heavy', 'bulky']
        }
        for con, patterns in cons_patterns.items():
            if any(pattern in text_lower for pattern in patterns):
                cons.append(con)
        return cons

    def analyze_all_reviews(self):
        """åˆ†ææ‰€æœ‰è¯„è®º - ä¿®å¤ç‰ˆ"""
        reviews = self.read_reviews()
        if not reviews:
            return False

        print(f"\nå¼€å§‹åˆ†æ {len(reviews)} æ¡è¯„è®º...")
        print("=" * 50)

        all_keywords = []
        all_pros = []
        all_cons = []

        # é€æ¡åˆ†æ
        for i, review in enumerate(reviews):
            if (i + 1) % 10 == 0:
                print(f"æ­£åœ¨åˆ†æç¬¬ {i + 1}/{len(reviews)} æ¡è¯„è®º...")

            # ä½¿ç”¨æ”¹è¿›çš„æœ¬åœ°åˆ†æï¼Œä¼ å…¥è¯„åˆ†ä¿¡æ¯
            result = self.local_sentiment_analysis(
                review['content'],
                review.get('rating', None)
            )

            self.results.append({
                'filename': review.get('filename', 'unknown'),
                'content': review['content'][:100] + '...' if len(review['content']) > 100 else review['content'],
                'sentiment': result['sentiment'],
                'score': result['score'],
                'keywords': result['keywords'],
                'pros': result['pros'],
                'cons': result['cons'],
                'summary': result['summary'],
                'original_rating': review.get('rating', None)
            })

            all_keywords.extend(result['keywords'])
            all_pros.extend(result['pros'])
            all_cons.extend(result['cons'])

        # æå–ä¸»é¢˜
        self.themes = self.extract_themes(all_keywords)
        self.product_insights = {
            'pros': Counter(all_pros).most_common(10),
            'cons': Counter(all_cons).most_common(10)
        }

        print("\nâœ“ åˆ†æå®Œæˆï¼")

        # è¾“å‡ºç»Ÿè®¡
        df = pd.DataFrame(self.results)
        sentiment_counts = df['sentiment'].value_counts()

        print(f"\næƒ…æ„Ÿåˆ†å¸ƒ:")
        total = len(self.results)
        for sentiment in ['positive', 'neutral', 'negative']:
            count = sentiment_counts.get(sentiment, 0)
            percentage = (count / total * 100) if total > 0 else 0
            bar = "â–ˆ" * int(percentage / 2)
            print(f"  {sentiment:8}: {count:3} æ¡ ({percentage:5.1f}%) {bar}")

        print("=" * 50)

        return True

    def extract_themes(self, all_keywords):
        """æå–ä¸»é¢˜"""
        keyword_freq = Counter(all_keywords)
        return keyword_freq.most_common(15)

    def generate_comprehensive_analysis(self):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        if not self.results:
            return ""

        df = pd.DataFrame(self.results)
        total_reviews = len(self.results)
        sentiment_counts = df['sentiment'].value_counts()
        avg_score = df['score'].mean()

        # è·å–åŸå§‹è¯„åˆ†çš„å¹³å‡å€¼
        original_ratings = [r['original_rating'] for r in self.results if r.get('original_rating')]
        avg_original_rating = sum(original_ratings) / len(original_ratings) if original_ratings else 0

        report = f"""
================================================================================
                        å•†å“ç»¼åˆè¯„ä»·åˆ†ææŠ¥å‘Š
================================================================================

ã€åŸºæœ¬ä¿¡æ¯ã€‘
åˆ†ææ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
åˆ†ææ¨¡å¼ï¼š{'DeepSeek APIåˆ†æ' if self.use_api else 'å¿«é€Ÿæœ¬åœ°åˆ†æ'}
åˆ†æè¯„è®ºæ•°ï¼š{total_reviews} æ¡
åŸå§‹å¹³å‡è¯„åˆ†ï¼š{avg_original_rating:.2f}/5.0 â­
åˆ†æå¹³å‡è¯„åˆ†ï¼š{avg_score:.2f}/5.0

ã€æ€»ä½“è¯„ä»·ã€‘
{'ä¼˜ç§€' if avg_score >= 4.0 else 'è‰¯å¥½' if avg_score >= 3.5 else 'ä¸€èˆ¬' if avg_score >= 3.0 else 'è¾ƒå·®'}

ã€æƒ…æ„Ÿåˆ†å¸ƒã€‘
ğŸ˜Š æ­£é¢è¯„ä»·ï¼š{sentiment_counts.get('positive', 0)} æ¡ ({sentiment_counts.get('positive', 0) / total_reviews * 100:.1f}%)
ğŸ˜ ä¸­æ€§è¯„ä»·ï¼š{sentiment_counts.get('neutral', 0)} æ¡ ({sentiment_counts.get('neutral', 0) / total_reviews * 100:.1f}%)
ğŸ˜ è´Ÿé¢è¯„ä»·ï¼š{sentiment_counts.get('negative', 0)} æ¡ ({sentiment_counts.get('negative', 0) / total_reviews * 100:.1f}%)

ã€æ ¸å¿ƒä¼˜åŠ¿ã€‘
"""
        if self.product_insights.get('pros'):
            for i, (pro, count) in enumerate(self.product_insights['pros'][:5], 1):
                report += f"  {i}. {pro} (æåŠ{count}æ¬¡)\n"
        else:
            report += "  æš‚æ— æ˜æ˜¾ä¼˜åŠ¿åé¦ˆ\n"

        report += "\nã€ä¸»è¦é—®é¢˜ã€‘\n"
        if self.product_insights.get('cons'):
            for i, (con, count) in enumerate(self.product_insights['cons'][:5], 1):
                report += f"  {i}. {con} (æåŠ{count}æ¬¡)\n"
        else:
            report += "  æš‚æ— æ˜æ˜¾é—®é¢˜åé¦ˆ\n"

        report += f"\nã€è´­ä¹°å»ºè®®ã€‘\n"
        if avg_score >= 4.0:
            report += "âœ… å¼ºçƒˆæ¨èï¼šè¯¥å•†å“è·å¾—äº†å¤§å¤šæ•°ç”¨æˆ·çš„é«˜åº¦è®¤å¯ã€‚\n"
        elif avg_score >= 3.5:
            report += "âœ… æ¨èè´­ä¹°ï¼šè¯¥å•†å“æ•´ä½“è¯„ä»·è‰¯å¥½ã€‚\n"
        elif avg_score >= 3.0:
            report += "âš ï¸ è°¨æ…è€ƒè™‘ï¼šè¯¥å•†å“è¯„ä»·ä¸€èˆ¬ï¼Œå­˜åœ¨ä¸€äº›é—®é¢˜ã€‚\n"
        else:
            report += "âŒ ä¸æ¨èï¼šè¯¥å•†å“å­˜åœ¨è¾ƒå¤šé—®é¢˜ï¼Œå»ºè®®é€‰æ‹©å…¶ä»–äº§å“ã€‚\n"

        # æ·»åŠ ä»£è¡¨æ€§è¯„è®º
        report += "\nã€ä»£è¡¨æ€§è¯„è®ºç¤ºä¾‹ã€‘\n"

        # æ­£é¢è¯„è®º
        positive_reviews = df[df['sentiment'] == 'positive'].head(2)
        if not positive_reviews.empty:
            report += "\næ­£é¢è¯„ä»·:\n"
            for _, row in positive_reviews.iterrows():
                report += f"  ã€Œ{row['summary'][:80]}...ã€\n"

        # è´Ÿé¢è¯„è®º
        negative_reviews = df[df['sentiment'] == 'negative'].head(2)
        if not negative_reviews.empty:
            report += "\nè´Ÿé¢è¯„ä»·:\n"
            for _, row in negative_reviews.iterrows():
                report += f"  ã€Œ{row['summary'][:80]}...ã€\n"

        report += "\n" + "=" * 80 + "\n"
        return report

    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Šå’Œå›¾è¡¨"""
        if not self.results:
            print("æ²¡æœ‰åˆ†æç»“æœ")
            return

        if not os.path.exists('analysis_results'):
            os.makedirs('analysis_results')

        # ç”ŸæˆCSV
        df = pd.DataFrame(self.results)
        df.to_csv('analysis_results/è¯¦ç»†åˆ†æç»“æœ.csv', index=False, encoding='utf-8-sig')

        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        report = self.generate_comprehensive_analysis()
        with open('analysis_results/å•†å“ç»¼åˆåˆ†ææŠ¥å‘Š.txt', 'w', encoding='utf-8') as f:
            f.write(report)
        print(report)

        # ç”Ÿæˆå¯è§†åŒ–
        self.generate_visualizations(df)

        print("\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° 'analysis_results' æ–‡ä»¶å¤¹")

    def generate_visualizations(self, df):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        try:
            sentiment_counts = df['sentiment'].value_counts()

            # æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
            plt.figure(figsize=(10, 6))
            colors = {'positive': '#2ecc71', 'negative': '#e74c3c', 'neutral': '#95a5a6'}

            if not sentiment_counts.empty:
                plt.pie(sentiment_counts.values,
                        labels=[f'{k}\n({v}æ¡)' for k, v in sentiment_counts.items()],
                        colors=[colors.get(k, '#95a5a6') for k in sentiment_counts.index],
                        autopct='%1.1f%%',
                        startangle=90)
                plt.title('è¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒ', fontsize=16, pad=20)

            plt.savefig('analysis_results/æƒ…æ„Ÿåˆ†å¸ƒå›¾.png', dpi=100, bbox_inches='tight')
            plt.close()

            # æƒ…æ„Ÿå¼ºåº¦åˆ†å¸ƒ
            plt.figure(figsize=(10, 6))
            plt.hist(df['score'], bins=10, edgecolor='black', alpha=0.7, color='skyblue')
            plt.xlabel('æƒ…æ„Ÿå¼ºåº¦', fontsize=12)
            plt.ylabel('è¯„è®ºæ•°é‡', fontsize=12)
            plt.title('æƒ…æ„Ÿå¼ºåº¦åˆ†å¸ƒ', fontsize=16, pad=20)
            plt.xticks([1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5])
            plt.grid(True, alpha=0.3)
            plt.axvline(df['score'].mean(), color='red', linestyle='dashed', linewidth=2,
                        label=f'å¹³å‡åˆ†: {df["score"].mean():.2f}')
            plt.legend()
            plt.savefig('analysis_results/æƒ…æ„Ÿå¼ºåº¦åˆ†å¸ƒ.png', dpi=100, bbox_inches='tight')
            plt.close()

            print("âœ“ å›¾è¡¨ç”ŸæˆæˆåŠŸ")
        except Exception as e:
            print(f"å›¾è¡¨ç”Ÿæˆæ—¶å‡ºç°é—®é¢˜: {e}")


def main():
    """ä¸»å‡½æ•°"""

    # ========== é…ç½®åŒºåŸŸ ==========
    CSV_FILE = "amazon_reviews.csv"
    API_KEY = "sk-a7dbc3801c44491c9081462edd4104fa"
    USE_API = True  # False = æœ¬åœ°åˆ†æ, True = APIåˆ†æ
    # ==============================

    print("=" * 60)
    print("     äºšé©¬é€Šè¯„è®ºæ™ºèƒ½åˆ†æç³»ç»Ÿ v6.0 (ä¿®å¤ç‰ˆ)")
    print("=" * 60)

    # æ­¥éª¤1: å¤„ç†CSVæ–‡ä»¶
    if os.path.exists(CSV_FILE):
        print(f"\n[æ­¥éª¤1] å¤„ç†CSVæ–‡ä»¶: {CSV_FILE}")

        converter = CSVToReviewsConverter(CSV_FILE, output_folder="reviews")
        if not converter.convert():
            print("CSVå¤„ç†å¤±è´¥")
            return

        print("\n" + "-" * 50)
    else:
        print(f"\næœªæ‰¾åˆ°CSVæ–‡ä»¶: {CSV_FILE}")
        return

    # æ­¥éª¤2: åˆ†æè¯„è®º
    print(f"\n[æ­¥éª¤2] å¼€å§‹åˆ†æè¯„è®º")
    print(f"æ¨¡å¼: {'DeepSeek APIåˆ†æ' if USE_API else 'å¿«é€Ÿæœ¬åœ°åˆ†æ'}")

    analyzer = AmazonReviewAnalyzer(API_KEY, reviews_folder="reviews", use_api=USE_API)

    start_time = time.time()
    success = analyzer.analyze_all_reviews()  # ä½¿ç”¨ä¿®å¤çš„åˆ†ææ–¹æ³•
    elapsed_time = time.time() - start_time

    if success and analyzer.results:
        print(f"\nâš¡ åˆ†æè€—æ—¶: {elapsed_time:.2f} ç§’")

        # æ­¥éª¤3: ç”ŸæˆæŠ¥å‘Š
        print(f"\n[æ­¥éª¤3] ç”Ÿæˆåˆ†ææŠ¥å‘Š")
        analyzer.generate_report()

        print("\n" + "=" * 60)
        print("          âœ… åˆ†æå®Œæˆï¼")
        print("=" * 60)
    else:
        print("\nåˆ†æå¤±è´¥")


if __name__ == "__main__":
    main()